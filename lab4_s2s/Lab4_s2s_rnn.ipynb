{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4 s2s rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnJhPvlUHMwN"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import json\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.switch_backend('agg')\n",
        "# import matplotlib.ticker as ticker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMXCcfixHZSf"
      },
      "source": [
        "device = torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\"\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "#----------Hyper Parameters----------#\n",
        "hidden_size = 256\n",
        "#The number of vocabulary\n",
        "vocab_size = 29\n",
        "teacher_forcing_ratio = 0.5\n",
        "LR = 0.0002\n",
        "MAX_LENGTH=512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KIduD7oHjTN"
      },
      "source": [
        "#Encoder\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size=torch.LongTensor(input_size)\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        # self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.gru = nn.LSTM(input_size=hidden_size,hidden_size=hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        # print(input[0].shape)\n",
        "        # embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, self.input_size)\n",
        "        output = embedded\n",
        "        output, (hidden,cell) = self.gru(output)\n",
        "        # output, hidden = self.gru(output,hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7je-W8i5nw8"
      },
      "source": [
        "#Decoder\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        # self.gru = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output[0])\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkywOBpXe1E"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        # self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.gru = nn.LSTM(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, (hidden,cell) = self.gru(output)\n",
        "        # output,hidden=self.gru(output,hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnGt6ubzSJyA"
      },
      "source": [
        "def get_pair(file):\n",
        "  with open('/content/drive/My Drive/Colab_Notebooks/lab4/'+file,'r') as f:\n",
        "    data=json.load(f)\n",
        "  pair=[]\n",
        "  for i in range(len(data)):\n",
        "    for j in range(len(data[i][\"input\"])):\n",
        "      arr=[data[i][\"input\"][j],data[i][\"target\"]]\n",
        "      pair.append(arr)\n",
        "  return np.array(pair)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgMglvhalZIR"
      },
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self):\n",
        "        self.char2idx = {'SOS': 0, 'EOS': 1,}\n",
        "        self.idx2char = {0: 'SOS', 1: 'EOS'}\n",
        "        for c in range(ord('a'), ord('z') + 1):\n",
        "          self.char2idx[chr(c)]=c-95\n",
        "          self.idx2char[c-95]=chr(c)\n",
        "        self.num_chars = 28\n",
        "\n",
        "    def sequence_to_indices(self, sequence, add_eos=False, add_sos=False):\n",
        "        \"\"\"Transform a char sequence to index sequence\n",
        "            :param sequence: a string composed with chars\n",
        "            :param add_eos: if true, add the <EOS> tag at the end of given sentence\n",
        "            :param add_sos: if true, add the <SOS> tag at the beginning of given sentence\n",
        "        \"\"\"\n",
        "        index_sequence = [self.char2idx['SOS']] if add_sos else []\n",
        "\n",
        "        for char in self.split_sequence(sequence):\n",
        "            if char not in self.char2idx:\n",
        "                index_sequence.append((self.char2idx['UNK']))\n",
        "            else:\n",
        "                index_sequence.append(self.char2idx[char])\n",
        "\n",
        "        if add_eos:\n",
        "            index_sequence.append(self.char2idx['EOS'])\n",
        "\n",
        "        return index_sequence\n",
        "\n",
        "    def indices_to_sequence(self, indices):\n",
        "        \"\"\"Transform a list of indices\n",
        "            :param indices: a list\n",
        "        \"\"\"\n",
        "        sequence = \"\"\n",
        "        for idx in indices:\n",
        "            char = self.idx2char[idx]\n",
        "            if char == \"EOS\":\n",
        "                break\n",
        "            else:\n",
        "                sequence += char\n",
        "        return sequence\n",
        "\n",
        "    def split_sequence(self, sequence):\n",
        "        \"\"\"Vary from languages and tasks. In our task, we simply return chars in given sentence\n",
        "        For example:\n",
        "            Input : alphabet\n",
        "            Return: [a, l, p, h, a, b, e, t]\n",
        "        \"\"\"\n",
        "        return [char for char in sequence]\n",
        "\n",
        "vocab=Vocabulary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCWSzXrDWhMw"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, word):\n",
        "  # indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes=[]\n",
        "  indexes.append(lang.word2index[word])\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "# def tensorsFromPair(pair):\n",
        "#   input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "#   target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "#   return (input_tensor, target_tensor)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = vocab.sequence_to_indices(pair[0],True)\n",
        "  input_tensor = torch.tensor(input_tensor, dtype=torch.long, device=device).view(-1, 1)\n",
        "  target_tensor = vocab.sequence_to_indices(pair[1],True)\n",
        "  target_tensor = torch.tensor(target_tensor, dtype=torch.long, device=device).view(-1, 1)\n",
        "  return (input_tensor, target_tensor)\n",
        "\n",
        "pairs=get_pair('train.json')\n",
        "# input,out=tensorsFromPair(pairs[0])\n",
        "# input.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV84hXuBOM3X"
      },
      "source": [
        "class VocabLoader(data.Dataset):\n",
        "    def __init__(self):\n",
        "        with open('train.json','r') as f:\n",
        "          self.data=json.load(f)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"'return the size of dataset\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      input=self.data[index][\"input\"]\n",
        "      for i in range(len(input)):\n",
        "        input[i]=list(input[i])\n",
        "        for j in range(len(input[i])):\n",
        "          input[i][j]=ord(input[i][j])-94\n",
        "        input[i].append(EOS_token)\n",
        "      input=torch.cuda.LongTensor(input,device=device)\n",
        "\n",
        "      target=self.data[index][\"target\"]\n",
        "      target=list(target)\n",
        "      for i in range(len(target)):\n",
        "        target[i]=ord(target[i])-95\n",
        "      target=torch.cuda.LongTensor(target,device=device)\n",
        "      return input,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxay19AFcXZC"
      },
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JNEViYM2dTD"
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "   \n",
        "    #----------sequence to sequence part for encoder----------#\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "      encoder_outputs[ei] = encoder_output[0, 0]\n",
        "    # encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
        "\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\t\n",
        "\n",
        "    #----------sequence to sequence part for decoder----------#\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # decoder_output, decoder_hidden = decoder(\n",
        "            #     decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # decoder_output, decoder_hidden = decoder(\n",
        "                # decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # try gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), 1)\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRPTJmc29j5N"
      },
      "source": [
        "def showPlot(points,iter):\n",
        "    # plt.figure()\n",
        "    # print(points,iter)\n",
        "    # fig, ax = plt.subplots()\n",
        "    # # this locator puts ticks at regular intervals\n",
        "    # loc = ticker.MultipleLocator(base=0.2)\n",
        "    # ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(iter,points)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HozxVkSl2-Sk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33136836-ffd4-44b2-b3bf-55fb0d1d8600"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    plot_iter=[]\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # your own dataloader\n",
        "    # with open('train.json', 'r') as f:\n",
        "    #   training_pairs = VocabLoader()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        # training_pair = training_pairs[iter - 1]\n",
        "        # input_tensor = training_pair[0]\n",
        "        # target_tensor = training_pair[1]\n",
        "        input_tensor,target_tensor=tensorsFromPair(random.choice(pairs))\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "            plot_iter.append(iter)\n",
        "\n",
        "    showPlot(plot_losses,plot_iter)\n",
        "\n",
        "# encoder1 = EncoderRNN(vocab_size, hidden_size).to(device)\n",
        "encoder1 = EncoderRNN(vocab_size, hidden_size).to(device)\n",
        "decoder1 = AttnDecoderRNN(hidden_size, vocab_size).to(device)\n",
        "trainIters(encoder1, decoder1,7000, print_every=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0m 0s (- 3m 53s) (10 0%) 3.3737\n",
            "0m 0s (- 4m 29s) (20 0%) 3.3585\n",
            "0m 1s (- 4m 25s) (30 0%) 3.3542\n",
            "0m 1s (- 4m 25s) (40 0%) 3.1752\n",
            "0m 1s (- 4m 24s) (50 0%) 3.2672\n",
            "0m 2s (- 4m 20s) (60 0%) 2.4204\n",
            "0m 2s (- 4m 18s) (70 1%) 3.2758\n",
            "0m 2s (- 4m 9s) (80 1%) 3.1791\n",
            "0m 3s (- 4m 5s) (90 1%) 2.8714\n",
            "0m 3s (- 4m 0s) (100 1%) 3.2310\n",
            "0m 3s (- 3m 56s) (110 1%) 2.6042\n",
            "0m 4s (- 3m 55s) (120 1%) 2.5485\n",
            "0m 4s (- 3m 57s) (130 1%) 3.2743\n",
            "0m 4s (- 3m 55s) (140 2%) 3.2502\n",
            "0m 5s (- 3m 56s) (150 2%) 3.2348\n",
            "0m 5s (- 3m 56s) (160 2%) 3.2365\n",
            "0m 5s (- 3m 56s) (170 2%) 3.2411\n",
            "0m 6s (- 3m 59s) (180 2%) 3.0515\n",
            "0m 6s (- 3m 58s) (190 2%) 2.9395\n",
            "0m 6s (- 3m 57s) (200 2%) 2.5485\n",
            "0m 7s (- 3m 56s) (210 3%) 3.1884\n",
            "0m 7s (- 3m 56s) (220 3%) 3.1754\n",
            "0m 7s (- 3m 55s) (230 3%) 3.1447\n",
            "0m 8s (- 3m 55s) (240 3%) 3.1532\n",
            "0m 8s (- 3m 56s) (250 3%) 2.8752\n",
            "0m 9s (- 3m 55s) (260 3%) 2.8381\n",
            "0m 9s (- 3m 53s) (270 3%) 2.1275\n",
            "0m 9s (- 3m 53s) (280 4%) 2.7863\n",
            "0m 10s (- 3m 52s) (290 4%) 2.4131\n",
            "0m 10s (- 3m 52s) (300 4%) 2.7204\n",
            "0m 10s (- 3m 51s) (310 4%) 2.4604\n",
            "0m 11s (- 3m 51s) (320 4%) 2.8347\n",
            "0m 11s (- 3m 51s) (330 4%) 2.8357\n",
            "0m 11s (- 3m 50s) (340 4%) 3.0691\n",
            "0m 12s (- 3m 51s) (350 5%) 3.0870\n",
            "0m 12s (- 3m 51s) (360 5%) 3.0389\n",
            "0m 12s (- 3m 51s) (370 5%) 2.9537\n",
            "0m 13s (- 3m 51s) (380 5%) 3.1156\n",
            "0m 13s (- 3m 51s) (390 5%) 2.9867\n",
            "0m 13s (- 3m 49s) (400 5%) 3.0046\n",
            "0m 14s (- 3m 48s) (410 5%) 3.0203\n",
            "0m 14s (- 3m 47s) (420 6%) 3.0021\n",
            "0m 14s (- 3m 48s) (430 6%) 3.0349\n",
            "0m 15s (- 3m 48s) (440 6%) 2.9533\n",
            "0m 15s (- 3m 48s) (450 6%) 3.0393\n",
            "0m 15s (- 3m 46s) (460 6%) 2.3759\n",
            "0m 16s (- 3m 44s) (470 6%) 1.8055\n",
            "0m 16s (- 3m 44s) (480 6%) 2.6325\n",
            "0m 16s (- 3m 43s) (490 7%) 2.7607\n",
            "0m 17s (- 3m 43s) (500 7%) 2.7876\n",
            "0m 17s (- 3m 42s) (510 7%) 3.0004\n",
            "0m 17s (- 3m 42s) (520 7%) 2.7292\n",
            "0m 18s (- 3m 41s) (530 7%) 2.5866\n",
            "0m 18s (- 3m 41s) (540 7%) 2.9667\n",
            "0m 18s (- 3m 42s) (550 7%) 3.0346\n",
            "0m 19s (- 3m 41s) (560 8%) 2.2577\n",
            "0m 19s (- 3m 41s) (570 8%) 3.0106\n",
            "0m 19s (- 3m 40s) (580 8%) 1.6861\n",
            "0m 20s (- 3m 40s) (590 8%) 2.6468\n",
            "0m 20s (- 3m 39s) (600 8%) 2.3001\n",
            "0m 20s (- 3m 39s) (610 8%) 2.3863\n",
            "0m 21s (- 3m 39s) (620 8%) 2.7602\n",
            "0m 21s (- 3m 37s) (630 9%) 1.9595\n",
            "0m 21s (- 3m 37s) (640 9%) 2.8034\n",
            "0m 22s (- 3m 37s) (650 9%) 2.9803\n",
            "0m 22s (- 3m 36s) (660 9%) 2.6240\n",
            "0m 22s (- 3m 35s) (670 9%) 2.5285\n",
            "0m 23s (- 3m 34s) (680 9%) 2.2386\n",
            "0m 23s (- 3m 33s) (690 9%) 2.4513\n",
            "0m 23s (- 3m 32s) (700 10%) 1.9082\n",
            "0m 23s (- 3m 32s) (710 10%) 2.3127\n",
            "0m 24s (- 3m 31s) (720 10%) 2.6647\n",
            "0m 24s (- 3m 30s) (730 10%) 2.1637\n",
            "0m 24s (- 3m 30s) (740 10%) 2.1311\n",
            "0m 25s (- 3m 29s) (750 10%) 2.9342\n",
            "0m 25s (- 3m 29s) (760 10%) 2.3699\n",
            "0m 25s (- 3m 29s) (770 11%) 2.9907\n",
            "0m 26s (- 3m 29s) (780 11%) 2.9457\n",
            "0m 26s (- 3m 29s) (790 11%) 2.9313\n",
            "0m 26s (- 3m 28s) (800 11%) 2.8715\n",
            "0m 27s (- 3m 28s) (810 11%) 2.8616\n",
            "0m 27s (- 3m 28s) (820 11%) 2.8859\n",
            "0m 28s (- 3m 28s) (830 11%) 2.8795\n",
            "0m 28s (- 3m 27s) (840 12%) 2.6606\n",
            "0m 28s (- 3m 27s) (850 12%) 2.6489\n",
            "0m 29s (- 3m 27s) (860 12%) 2.8970\n",
            "0m 29s (- 3m 27s) (870 12%) 3.0095\n",
            "0m 29s (- 3m 27s) (880 12%) 2.9638\n",
            "0m 30s (- 3m 26s) (890 12%) 2.2625\n",
            "0m 30s (- 3m 27s) (900 12%) 2.9649\n",
            "0m 30s (- 3m 26s) (910 13%) 2.7126\n",
            "0m 31s (- 3m 26s) (920 13%) 2.8534\n",
            "0m 31s (- 3m 26s) (930 13%) 2.7015\n",
            "0m 31s (- 3m 25s) (940 13%) 2.1535\n",
            "0m 32s (- 3m 24s) (950 13%) 2.1982\n",
            "0m 32s (- 3m 24s) (960 13%) 2.6149\n",
            "0m 32s (- 3m 24s) (970 13%) 2.7386\n",
            "0m 33s (- 3m 23s) (980 14%) 2.5022\n",
            "0m 33s (- 3m 23s) (990 14%) 2.5921\n",
            "0m 33s (- 3m 23s) (1000 14%) 2.2423\n",
            "0m 34s (- 3m 23s) (1010 14%) 2.8867\n",
            "0m 34s (- 3m 23s) (1020 14%) 2.8634\n",
            "0m 35s (- 3m 23s) (1030 14%) 2.9514\n",
            "0m 35s (- 3m 22s) (1040 14%) 2.4177\n",
            "0m 35s (- 3m 22s) (1050 15%) 2.3271\n",
            "0m 35s (- 3m 21s) (1060 15%) 1.8226\n",
            "0m 36s (- 3m 20s) (1070 15%) 2.2691\n",
            "0m 36s (- 3m 19s) (1080 15%) 1.5588\n",
            "0m 36s (- 3m 19s) (1090 15%) 2.8267\n",
            "0m 37s (- 3m 19s) (1100 15%) 2.9294\n",
            "0m 37s (- 3m 18s) (1110 15%) 2.9326\n",
            "0m 37s (- 3m 18s) (1120 16%) 2.8724\n",
            "0m 38s (- 3m 18s) (1130 16%) 2.1747\n",
            "0m 38s (- 3m 18s) (1140 16%) 2.6711\n",
            "0m 38s (- 3m 17s) (1150 16%) 2.6962\n",
            "0m 39s (- 3m 17s) (1160 16%) 2.5668\n",
            "0m 39s (- 3m 17s) (1170 16%) 2.7113\n",
            "0m 39s (- 3m 16s) (1180 16%) 2.3065\n",
            "0m 40s (- 3m 16s) (1190 17%) 2.3981\n",
            "0m 40s (- 3m 16s) (1200 17%) 2.9457\n",
            "0m 40s (- 3m 15s) (1210 17%) 2.9415\n",
            "0m 41s (- 3m 15s) (1220 17%) 2.7690\n",
            "0m 41s (- 3m 15s) (1230 17%) 2.8921\n",
            "0m 41s (- 3m 14s) (1240 17%) 2.8639\n",
            "0m 42s (- 3m 14s) (1250 17%) 2.7417\n",
            "0m 42s (- 3m 13s) (1260 18%) 2.7267\n",
            "0m 42s (- 3m 13s) (1270 18%) 2.5198\n",
            "0m 43s (- 3m 12s) (1280 18%) 2.6690\n",
            "0m 43s (- 3m 12s) (1290 18%) 2.7987\n",
            "0m 43s (- 3m 11s) (1300 18%) 2.3303\n",
            "0m 44s (- 3m 11s) (1310 18%) 2.8609\n",
            "0m 44s (- 3m 11s) (1320 18%) 2.8463\n",
            "0m 44s (- 3m 11s) (1330 19%) 2.4735\n",
            "0m 45s (- 3m 10s) (1340 19%) 2.1904\n",
            "0m 45s (- 3m 10s) (1350 19%) 2.6350\n",
            "0m 45s (- 3m 10s) (1360 19%) 2.8572\n",
            "0m 46s (- 3m 9s) (1370 19%) 2.5674\n",
            "0m 46s (- 3m 9s) (1380 19%) 2.6608\n",
            "0m 46s (- 3m 8s) (1390 19%) 2.0756\n",
            "0m 47s (- 3m 8s) (1400 20%) 2.6351\n",
            "0m 47s (- 3m 7s) (1410 20%) 2.3516\n",
            "0m 47s (- 3m 7s) (1420 20%) 2.5608\n",
            "0m 47s (- 3m 6s) (1430 20%) 2.7533\n",
            "0m 48s (- 3m 6s) (1440 20%) 2.7432\n",
            "0m 48s (- 3m 6s) (1450 20%) 2.8663\n",
            "0m 48s (- 3m 5s) (1460 20%) 1.7722\n",
            "0m 49s (- 3m 4s) (1470 21%) 1.9780\n",
            "0m 49s (- 3m 4s) (1480 21%) 1.8674\n",
            "0m 49s (- 3m 4s) (1490 21%) 2.1281\n",
            "0m 50s (- 3m 3s) (1500 21%) 1.5835\n",
            "0m 50s (- 3m 2s) (1510 21%) 1.9217\n",
            "0m 50s (- 3m 2s) (1520 21%) 2.0306\n",
            "0m 50s (- 3m 1s) (1530 21%) 2.0611\n",
            "0m 51s (- 3m 1s) (1540 22%) 2.1897\n",
            "0m 51s (- 3m 0s) (1550 22%) 2.2102\n",
            "0m 51s (- 3m 0s) (1560 22%) 2.2334\n",
            "0m 52s (- 2m 59s) (1570 22%) 2.1617\n",
            "0m 52s (- 2m 59s) (1580 22%) 2.4662\n",
            "0m 52s (- 2m 59s) (1590 22%) 2.7666\n",
            "0m 53s (- 2m 59s) (1600 22%) 2.8790\n",
            "0m 53s (- 2m 58s) (1610 23%) 2.4009\n",
            "0m 53s (- 2m 58s) (1620 23%) 3.0102\n",
            "0m 54s (- 2m 58s) (1630 23%) 2.8167\n",
            "0m 54s (- 2m 57s) (1640 23%) 2.3426\n",
            "0m 54s (- 2m 57s) (1650 23%) 2.2842\n",
            "0m 55s (- 2m 57s) (1660 23%) 2.0530\n",
            "0m 55s (- 2m 56s) (1670 23%) 1.9998\n",
            "0m 55s (- 2m 55s) (1680 24%) 1.4353\n",
            "0m 55s (- 2m 55s) (1690 24%) 1.7651\n",
            "0m 56s (- 2m 54s) (1700 24%) 1.7375\n",
            "0m 56s (- 2m 54s) (1710 24%) 2.2359\n",
            "0m 56s (- 2m 54s) (1720 24%) 2.3318\n",
            "0m 56s (- 2m 53s) (1730 24%) 1.7433\n",
            "0m 57s (- 2m 53s) (1740 24%) 2.2380\n",
            "0m 57s (- 2m 52s) (1750 25%) 2.0934\n",
            "0m 57s (- 2m 52s) (1760 25%) 2.1697\n",
            "0m 58s (- 2m 52s) (1770 25%) 2.7867\n",
            "0m 58s (- 2m 51s) (1780 25%) 1.8938\n",
            "0m 58s (- 2m 51s) (1790 25%) 2.1761\n",
            "0m 59s (- 2m 50s) (1800 25%) 2.4590\n",
            "0m 59s (- 2m 50s) (1810 25%) 2.2122\n",
            "0m 59s (- 2m 50s) (1820 26%) 2.7315\n",
            "1m 0s (- 2m 49s) (1830 26%) 2.4634\n",
            "1m 0s (- 2m 49s) (1840 26%) 2.5134\n",
            "1m 0s (- 2m 48s) (1850 26%) 2.0158\n",
            "1m 0s (- 2m 48s) (1860 26%) 1.9455\n",
            "1m 1s (- 2m 47s) (1870 26%) 1.9613\n",
            "1m 1s (- 2m 47s) (1880 26%) 2.2673\n",
            "1m 1s (- 2m 46s) (1890 27%) 2.0666\n",
            "1m 1s (- 2m 46s) (1900 27%) 1.7381\n",
            "1m 2s (- 2m 45s) (1910 27%) 1.9495\n",
            "1m 2s (- 2m 45s) (1920 27%) 1.6959\n",
            "1m 2s (- 2m 44s) (1930 27%) 1.7529\n",
            "1m 3s (- 2m 44s) (1940 27%) 2.0235\n",
            "1m 3s (- 2m 44s) (1950 27%) 1.7421\n",
            "1m 3s (- 2m 43s) (1960 28%) 1.5732\n",
            "1m 3s (- 2m 43s) (1970 28%) 2.2625\n",
            "1m 4s (- 2m 42s) (1980 28%) 2.4996\n",
            "1m 4s (- 2m 42s) (1990 28%) 2.0662\n",
            "1m 4s (- 2m 42s) (2000 28%) 2.7480\n",
            "1m 5s (- 2m 41s) (2010 28%) 2.1998\n",
            "1m 5s (- 2m 41s) (2020 28%) 2.2260\n",
            "1m 5s (- 2m 41s) (2030 28%) 2.0787\n",
            "1m 6s (- 2m 40s) (2040 29%) 2.3731\n",
            "1m 6s (- 2m 40s) (2050 29%) 2.5857\n",
            "1m 6s (- 2m 39s) (2060 29%) 2.0103\n",
            "1m 6s (- 2m 39s) (2070 29%) 2.1884\n",
            "1m 7s (- 2m 39s) (2080 29%) 1.8150\n",
            "1m 7s (- 2m 38s) (2090 29%) 2.8473\n",
            "1m 7s (- 2m 38s) (2100 30%) 2.1028\n",
            "1m 8s (- 2m 38s) (2110 30%) 1.8867\n",
            "1m 8s (- 2m 37s) (2120 30%) 2.0637\n",
            "1m 8s (- 2m 37s) (2130 30%) 1.9770\n",
            "1m 9s (- 2m 36s) (2140 30%) 2.1105\n",
            "1m 9s (- 2m 36s) (2150 30%) 2.4479\n",
            "1m 9s (- 2m 36s) (2160 30%) 1.9725\n",
            "1m 9s (- 2m 35s) (2170 31%) 2.2189\n",
            "1m 10s (- 2m 35s) (2180 31%) 2.6321\n",
            "1m 10s (- 2m 35s) (2190 31%) 2.6166\n",
            "1m 10s (- 2m 34s) (2200 31%) 2.1410\n",
            "1m 11s (- 2m 34s) (2210 31%) 2.6502\n",
            "1m 11s (- 2m 34s) (2220 31%) 2.6518\n",
            "1m 12s (- 2m 34s) (2230 31%) 2.4594\n",
            "1m 12s (- 2m 33s) (2240 32%) 2.3611\n",
            "1m 12s (- 2m 33s) (2250 32%) 2.7759\n",
            "1m 13s (- 2m 33s) (2260 32%) 2.4850\n",
            "1m 13s (- 2m 33s) (2270 32%) 2.2832\n",
            "1m 13s (- 2m 32s) (2280 32%) 1.9946\n",
            "1m 14s (- 2m 32s) (2290 32%) 2.6537\n",
            "1m 14s (- 2m 32s) (2300 32%) 2.3490\n",
            "1m 14s (- 2m 32s) (2310 33%) 2.1394\n",
            "1m 15s (- 2m 31s) (2320 33%) 2.1999\n",
            "1m 15s (- 2m 31s) (2330 33%) 2.4233\n",
            "1m 15s (- 2m 31s) (2340 33%) 2.1665\n",
            "1m 16s (- 2m 30s) (2350 33%) 1.9768\n",
            "1m 16s (- 2m 30s) (2360 33%) 1.9653\n",
            "1m 16s (- 2m 30s) (2370 33%) 2.2303\n",
            "1m 17s (- 2m 29s) (2380 34%) 2.1399\n",
            "1m 17s (- 2m 29s) (2390 34%) 2.5291\n",
            "1m 17s (- 2m 29s) (2400 34%) 2.3685\n",
            "1m 18s (- 2m 28s) (2410 34%) 2.3266\n",
            "1m 18s (- 2m 28s) (2420 34%) 2.5285\n",
            "1m 18s (- 2m 28s) (2430 34%) 2.1056\n",
            "1m 19s (- 2m 27s) (2440 34%) 2.5430\n",
            "1m 19s (- 2m 27s) (2450 35%) 1.9876\n",
            "1m 19s (- 2m 27s) (2460 35%) 2.0531\n",
            "1m 20s (- 2m 27s) (2470 35%) 2.5662\n",
            "1m 20s (- 2m 26s) (2480 35%) 2.2327\n",
            "1m 20s (- 2m 26s) (2490 35%) 2.2753\n",
            "1m 21s (- 2m 26s) (2500 35%) 2.5702\n",
            "1m 21s (- 2m 25s) (2510 35%) 2.4059\n",
            "1m 21s (- 2m 25s) (2520 36%) 2.1861\n",
            "1m 22s (- 2m 25s) (2530 36%) 2.5300\n",
            "1m 22s (- 2m 24s) (2540 36%) 2.1110\n",
            "1m 22s (- 2m 24s) (2550 36%) 2.6185\n",
            "1m 23s (- 2m 24s) (2560 36%) 2.6644\n",
            "1m 23s (- 2m 23s) (2570 36%) 2.6923\n",
            "1m 23s (- 2m 23s) (2580 36%) 2.4852\n",
            "1m 24s (- 2m 23s) (2590 37%) 2.0668\n",
            "1m 24s (- 2m 22s) (2600 37%) 2.5889\n",
            "1m 24s (- 2m 22s) (2610 37%) 2.4658\n",
            "1m 25s (- 2m 22s) (2620 37%) 2.3737\n",
            "1m 25s (- 2m 21s) (2630 37%) 1.9679\n",
            "1m 25s (- 2m 21s) (2640 37%) 2.2723\n",
            "1m 26s (- 2m 21s) (2650 37%) 2.1354\n",
            "1m 26s (- 2m 20s) (2660 38%) 2.5115\n",
            "1m 26s (- 2m 20s) (2670 38%) 2.6238\n",
            "1m 27s (- 2m 20s) (2680 38%) 2.8190\n",
            "1m 27s (- 2m 20s) (2690 38%) 2.6753\n",
            "1m 27s (- 2m 19s) (2700 38%) 2.7172\n",
            "1m 28s (- 2m 19s) (2710 38%) 2.6920\n",
            "1m 28s (- 2m 19s) (2720 38%) 2.7844\n",
            "1m 28s (- 2m 18s) (2730 39%) 2.4313\n",
            "1m 29s (- 2m 18s) (2740 39%) 1.9578\n",
            "1m 29s (- 2m 18s) (2750 39%) 1.6129\n",
            "1m 29s (- 2m 17s) (2760 39%) 1.9552\n",
            "1m 29s (- 2m 17s) (2770 39%) 1.9025\n",
            "1m 30s (- 2m 16s) (2780 39%) 2.4683\n",
            "1m 30s (- 2m 16s) (2790 39%) 2.7620\n",
            "1m 30s (- 2m 16s) (2800 40%) 2.4576\n",
            "1m 31s (- 2m 16s) (2810 40%) 2.7904\n",
            "1m 31s (- 2m 16s) (2820 40%) 2.6159\n",
            "1m 32s (- 2m 15s) (2830 40%) 2.6190\n",
            "1m 32s (- 2m 15s) (2840 40%) 1.8872\n",
            "1m 32s (- 2m 14s) (2850 40%) 2.2871\n",
            "1m 33s (- 2m 14s) (2860 40%) 2.3560\n",
            "1m 33s (- 2m 14s) (2870 41%) 2.4635\n",
            "1m 33s (- 2m 14s) (2880 41%) 2.5596\n",
            "1m 34s (- 2m 13s) (2890 41%) 2.4641\n",
            "1m 34s (- 2m 13s) (2900 41%) 2.4429\n",
            "1m 34s (- 2m 13s) (2910 41%) 1.9999\n",
            "1m 34s (- 2m 12s) (2920 41%) 2.4911\n",
            "1m 35s (- 2m 12s) (2930 41%) 2.1447\n",
            "1m 35s (- 2m 12s) (2940 42%) 2.6679\n",
            "1m 36s (- 2m 11s) (2950 42%) 2.6425\n",
            "1m 36s (- 2m 11s) (2960 42%) 2.4849\n",
            "1m 36s (- 2m 11s) (2970 42%) 2.3830\n",
            "1m 36s (- 2m 10s) (2980 42%) 1.5863\n",
            "1m 37s (- 2m 10s) (2990 42%) 1.8310\n",
            "1m 37s (- 2m 10s) (3000 42%) 1.6863\n",
            "1m 37s (- 2m 9s) (3010 43%) 2.3170\n",
            "1m 38s (- 2m 9s) (3020 43%) 2.6906\n",
            "1m 38s (- 2m 9s) (3030 43%) 2.2591\n",
            "1m 38s (- 2m 8s) (3040 43%) 2.5370\n",
            "1m 39s (- 2m 8s) (3050 43%) 2.3868\n",
            "1m 39s (- 2m 8s) (3060 43%) 1.9297\n",
            "1m 39s (- 2m 7s) (3070 43%) 2.4915\n",
            "1m 40s (- 2m 7s) (3080 44%) 2.2938\n",
            "1m 40s (- 2m 7s) (3090 44%) 2.0733\n",
            "1m 40s (- 2m 6s) (3100 44%) 2.5149\n",
            "1m 41s (- 2m 6s) (3110 44%) 2.0904\n",
            "1m 41s (- 2m 5s) (3120 44%) 1.9314\n",
            "1m 41s (- 2m 5s) (3130 44%) 2.0428\n",
            "1m 41s (- 2m 5s) (3140 44%) 2.2884\n",
            "1m 42s (- 2m 4s) (3150 45%) 2.3979\n",
            "1m 42s (- 2m 4s) (3160 45%) 2.3256\n",
            "1m 42s (- 2m 4s) (3170 45%) 2.4718\n",
            "1m 43s (- 2m 4s) (3180 45%) 2.6307\n",
            "1m 43s (- 2m 3s) (3190 45%) 2.4618\n",
            "1m 44s (- 2m 3s) (3200 45%) 2.4765\n",
            "1m 44s (- 2m 3s) (3210 45%) 2.3050\n",
            "1m 44s (- 2m 2s) (3220 46%) 2.2827\n",
            "1m 45s (- 2m 2s) (3230 46%) 2.7408\n",
            "1m 45s (- 2m 2s) (3240 46%) 2.4546\n",
            "1m 45s (- 2m 1s) (3250 46%) 2.3743\n",
            "1m 46s (- 2m 1s) (3260 46%) 2.3493\n",
            "1m 46s (- 2m 1s) (3270 46%) 2.4910\n",
            "1m 46s (- 2m 1s) (3280 46%) 2.3167\n",
            "1m 46s (- 2m 0s) (3290 47%) 1.9431\n",
            "1m 47s (- 2m 0s) (3300 47%) 2.0267\n",
            "1m 47s (- 1m 59s) (3310 47%) 2.2838\n",
            "1m 47s (- 1m 59s) (3320 47%) 2.0669\n",
            "1m 48s (- 1m 59s) (3330 47%) 2.1824\n",
            "1m 48s (- 1m 58s) (3340 47%) 2.2514\n",
            "1m 48s (- 1m 58s) (3350 47%) 1.9180\n",
            "1m 49s (- 1m 58s) (3360 48%) 2.2143\n",
            "1m 49s (- 1m 57s) (3370 48%) 2.5441\n",
            "1m 49s (- 1m 57s) (3380 48%) 2.2571\n",
            "1m 50s (- 1m 57s) (3390 48%) 2.4574\n",
            "1m 50s (- 1m 57s) (3400 48%) 2.5864\n",
            "1m 50s (- 1m 56s) (3410 48%) 1.8607\n",
            "1m 51s (- 1m 56s) (3420 48%) 2.1663\n",
            "1m 51s (- 1m 56s) (3430 49%) 2.3948\n",
            "1m 51s (- 1m 55s) (3440 49%) 2.4359\n",
            "1m 52s (- 1m 55s) (3450 49%) 2.1054\n",
            "1m 52s (- 1m 54s) (3460 49%) 2.3852\n",
            "1m 52s (- 1m 54s) (3470 49%) 2.4918\n",
            "1m 53s (- 1m 54s) (3480 49%) 2.1500\n",
            "1m 53s (- 1m 53s) (3490 49%) 2.0170\n",
            "1m 53s (- 1m 53s) (3500 50%) 2.4487\n",
            "1m 53s (- 1m 53s) (3510 50%) 2.4702\n",
            "1m 54s (- 1m 52s) (3520 50%) 2.1912\n",
            "1m 54s (- 1m 52s) (3530 50%) 2.4002\n",
            "1m 54s (- 1m 52s) (3540 50%) 2.4180\n",
            "1m 55s (- 1m 52s) (3550 50%) 2.5809\n",
            "1m 55s (- 1m 51s) (3560 50%) 2.4222\n",
            "1m 55s (- 1m 51s) (3570 51%) 2.1816\n",
            "1m 56s (- 1m 51s) (3580 51%) 2.4899\n",
            "1m 56s (- 1m 50s) (3590 51%) 2.3033\n",
            "1m 56s (- 1m 50s) (3600 51%) 2.2032\n",
            "1m 57s (- 1m 50s) (3610 51%) 1.9816\n",
            "1m 57s (- 1m 49s) (3620 51%) 2.0787\n",
            "1m 57s (- 1m 49s) (3630 51%) 2.2625\n",
            "1m 58s (- 1m 49s) (3640 52%) 2.0360\n",
            "1m 58s (- 1m 48s) (3650 52%) 1.7951\n",
            "1m 58s (- 1m 48s) (3660 52%) 1.9058\n",
            "1m 59s (- 1m 48s) (3670 52%) 2.0377\n",
            "1m 59s (- 1m 47s) (3680 52%) 2.0974\n",
            "1m 59s (- 1m 47s) (3690 52%) 2.2778\n",
            "1m 59s (- 1m 46s) (3700 52%) 1.6357\n",
            "2m 0s (- 1m 46s) (3710 53%) 2.0922\n",
            "2m 0s (- 1m 46s) (3720 53%) 2.2568\n",
            "2m 0s (- 1m 45s) (3730 53%) 2.7534\n",
            "2m 1s (- 1m 45s) (3740 53%) 2.6488\n",
            "2m 1s (- 1m 45s) (3750 53%) 2.7515\n",
            "2m 1s (- 1m 45s) (3760 53%) 2.3576\n",
            "2m 2s (- 1m 44s) (3770 53%) 2.4718\n",
            "2m 2s (- 1m 44s) (3780 54%) 2.2801\n",
            "2m 2s (- 1m 44s) (3790 54%) 2.5910\n",
            "2m 3s (- 1m 43s) (3800 54%) 2.0697\n",
            "2m 3s (- 1m 43s) (3810 54%) 2.4230\n",
            "2m 3s (- 1m 43s) (3820 54%) 2.4149\n",
            "2m 4s (- 1m 42s) (3830 54%) 2.3672\n",
            "2m 4s (- 1m 42s) (3840 54%) 2.1712\n",
            "2m 4s (- 1m 42s) (3850 55%) 2.0214\n",
            "2m 5s (- 1m 41s) (3860 55%) 1.9757\n",
            "2m 5s (- 1m 41s) (3870 55%) 1.8848\n",
            "2m 5s (- 1m 41s) (3880 55%) 2.1801\n",
            "2m 6s (- 1m 40s) (3890 55%) 1.7533\n",
            "2m 6s (- 1m 40s) (3900 55%) 2.3526\n",
            "2m 6s (- 1m 40s) (3910 55%) 2.2389\n",
            "2m 7s (- 1m 39s) (3920 56%) 1.8249\n",
            "2m 7s (- 1m 39s) (3930 56%) 2.1643\n",
            "2m 7s (- 1m 39s) (3940 56%) 1.7642\n",
            "2m 7s (- 1m 38s) (3950 56%) 1.3284\n",
            "2m 8s (- 1m 38s) (3960 56%) 2.3602\n",
            "2m 8s (- 1m 38s) (3970 56%) 1.6816\n",
            "2m 8s (- 1m 37s) (3980 56%) 1.7749\n",
            "2m 9s (- 1m 37s) (3990 56%) 1.8910\n",
            "2m 9s (- 1m 37s) (4000 57%) 2.1745\n",
            "2m 9s (- 1m 36s) (4010 57%) 1.6134\n",
            "2m 10s (- 1m 36s) (4020 57%) 1.8018\n",
            "2m 10s (- 1m 36s) (4030 57%) 2.4472\n",
            "2m 10s (- 1m 35s) (4040 57%) 1.9940\n",
            "2m 10s (- 1m 35s) (4050 57%) 2.1721\n",
            "2m 11s (- 1m 35s) (4060 57%) 2.1705\n",
            "2m 11s (- 1m 34s) (4070 58%) 1.8877\n",
            "2m 11s (- 1m 34s) (4080 58%) 1.7471\n",
            "2m 12s (- 1m 34s) (4090 58%) 1.7945\n",
            "2m 12s (- 1m 33s) (4100 58%) 1.6390\n",
            "2m 12s (- 1m 33s) (4110 58%) 1.8440\n",
            "2m 13s (- 1m 33s) (4120 58%) 1.7841\n",
            "2m 13s (- 1m 32s) (4130 59%) 2.0945\n",
            "2m 13s (- 1m 32s) (4140 59%) 2.0864\n",
            "2m 13s (- 1m 31s) (4150 59%) 1.9365\n",
            "2m 14s (- 1m 31s) (4160 59%) 1.9697\n",
            "2m 14s (- 1m 31s) (4170 59%) 1.4696\n",
            "2m 14s (- 1m 30s) (4180 59%) 1.8554\n",
            "2m 15s (- 1m 30s) (4190 59%) 2.1099\n",
            "2m 15s (- 1m 30s) (4200 60%) 2.3498\n",
            "2m 15s (- 1m 29s) (4210 60%) 2.2504\n",
            "2m 16s (- 1m 29s) (4220 60%) 1.9651\n",
            "2m 16s (- 1m 29s) (4230 60%) 2.0585\n",
            "2m 16s (- 1m 28s) (4240 60%) 2.2302\n",
            "2m 17s (- 1m 28s) (4250 60%) 2.2001\n",
            "2m 17s (- 1m 28s) (4260 60%) 2.1311\n",
            "2m 17s (- 1m 27s) (4270 61%) 2.1111\n",
            "2m 17s (- 1m 27s) (4280 61%) 2.0760\n",
            "2m 18s (- 1m 27s) (4290 61%) 2.1212\n",
            "2m 18s (- 1m 26s) (4300 61%) 2.2765\n",
            "2m 18s (- 1m 26s) (4310 61%) 2.3092\n",
            "2m 19s (- 1m 26s) (4320 61%) 2.0511\n",
            "2m 19s (- 1m 25s) (4330 61%) 2.1545\n",
            "2m 19s (- 1m 25s) (4340 62%) 2.2328\n",
            "2m 19s (- 1m 25s) (4350 62%) 1.8353\n",
            "2m 20s (- 1m 24s) (4360 62%) 2.1434\n",
            "2m 20s (- 1m 24s) (4370 62%) 1.8537\n",
            "2m 20s (- 1m 24s) (4380 62%) 2.3382\n",
            "2m 21s (- 1m 23s) (4390 62%) 2.0489\n",
            "2m 21s (- 1m 23s) (4400 62%) 2.1256\n",
            "2m 21s (- 1m 23s) (4410 63%) 1.6807\n",
            "2m 22s (- 1m 22s) (4420 63%) 1.6815\n",
            "2m 22s (- 1m 22s) (4430 63%) 2.2073\n",
            "2m 22s (- 1m 22s) (4440 63%) 2.0866\n",
            "2m 22s (- 1m 21s) (4450 63%) 2.4406\n",
            "2m 23s (- 1m 21s) (4460 63%) 1.5442\n",
            "2m 23s (- 1m 21s) (4470 63%) 2.0198\n",
            "2m 23s (- 1m 20s) (4480 64%) 1.8019\n",
            "2m 24s (- 1m 20s) (4490 64%) 2.1402\n",
            "2m 24s (- 1m 20s) (4500 64%) 1.7765\n",
            "2m 24s (- 1m 19s) (4510 64%) 2.3371\n",
            "2m 25s (- 1m 19s) (4520 64%) 1.9415\n",
            "2m 25s (- 1m 19s) (4530 64%) 1.8321\n",
            "2m 25s (- 1m 18s) (4540 64%) 1.7280\n",
            "2m 25s (- 1m 18s) (4550 65%) 2.0648\n",
            "2m 26s (- 1m 18s) (4560 65%) 1.7915\n",
            "2m 26s (- 1m 17s) (4570 65%) 2.3311\n",
            "2m 26s (- 1m 17s) (4580 65%) 2.1858\n",
            "2m 27s (- 1m 17s) (4590 65%) 2.2487\n",
            "2m 27s (- 1m 16s) (4600 65%) 2.0728\n",
            "2m 27s (- 1m 16s) (4610 65%) 1.6811\n",
            "2m 27s (- 1m 16s) (4620 66%) 2.0315\n",
            "2m 28s (- 1m 15s) (4630 66%) 1.6063\n",
            "2m 28s (- 1m 15s) (4640 66%) 2.2567\n",
            "2m 28s (- 1m 15s) (4650 66%) 2.1867\n",
            "2m 29s (- 1m 14s) (4660 66%) 2.3389\n",
            "2m 29s (- 1m 14s) (4670 66%) 2.4002\n",
            "2m 29s (- 1m 14s) (4680 66%) 2.1071\n",
            "2m 30s (- 1m 13s) (4690 67%) 2.1495\n",
            "2m 30s (- 1m 13s) (4700 67%) 2.2527\n",
            "2m 30s (- 1m 13s) (4710 67%) 1.8286\n",
            "2m 31s (- 1m 13s) (4720 67%) 1.9991\n",
            "2m 31s (- 1m 12s) (4730 67%) 1.9540\n",
            "2m 31s (- 1m 12s) (4740 67%) 2.0334\n",
            "2m 32s (- 1m 12s) (4750 67%) 2.0221\n",
            "2m 32s (- 1m 11s) (4760 68%) 1.1210\n",
            "2m 32s (- 1m 11s) (4770 68%) 1.7435\n",
            "2m 32s (- 1m 10s) (4780 68%) 1.7931\n",
            "2m 33s (- 1m 10s) (4790 68%) 1.6762\n",
            "2m 33s (- 1m 10s) (4800 68%) 1.7398\n",
            "2m 33s (- 1m 10s) (4810 68%) 2.1849\n",
            "2m 34s (- 1m 9s) (4820 68%) 1.9707\n",
            "2m 34s (- 1m 9s) (4830 69%) 1.7939\n",
            "2m 34s (- 1m 9s) (4840 69%) 1.8112\n",
            "2m 35s (- 1m 8s) (4850 69%) 1.8515\n",
            "2m 35s (- 1m 8s) (4860 69%) 1.9194\n",
            "2m 35s (- 1m 8s) (4870 69%) 2.3671\n",
            "2m 35s (- 1m 7s) (4880 69%) 1.9086\n",
            "2m 36s (- 1m 7s) (4890 69%) 1.9099\n",
            "2m 36s (- 1m 7s) (4900 70%) 1.7930\n",
            "2m 36s (- 1m 6s) (4910 70%) 1.9226\n",
            "2m 37s (- 1m 6s) (4920 70%) 1.9046\n",
            "2m 37s (- 1m 6s) (4930 70%) 2.4301\n",
            "2m 37s (- 1m 5s) (4940 70%) 2.1584\n",
            "2m 38s (- 1m 5s) (4950 70%) 2.1127\n",
            "2m 38s (- 1m 5s) (4960 70%) 2.0851\n",
            "2m 38s (- 1m 4s) (4970 71%) 1.6663\n",
            "2m 38s (- 1m 4s) (4980 71%) 1.7781\n",
            "2m 39s (- 1m 4s) (4990 71%) 2.0526\n",
            "2m 39s (- 1m 3s) (5000 71%) 1.5785\n",
            "2m 39s (- 1m 3s) (5010 71%) 1.9376\n",
            "2m 39s (- 1m 3s) (5020 71%) 2.0119\n",
            "2m 40s (- 1m 2s) (5030 71%) 1.2700\n",
            "2m 40s (- 1m 2s) (5040 72%) 1.9877\n",
            "2m 40s (- 1m 2s) (5050 72%) 1.8705\n",
            "2m 41s (- 1m 1s) (5060 72%) 1.8736\n",
            "2m 41s (- 1m 1s) (5070 72%) 1.4748\n",
            "2m 41s (- 1m 1s) (5080 72%) 2.2549\n",
            "2m 41s (- 1m 0s) (5090 72%) 2.0774\n",
            "2m 42s (- 1m 0s) (5100 72%) 1.9929\n",
            "2m 42s (- 1m 0s) (5110 73%) 1.7505\n",
            "2m 42s (- 0m 59s) (5120 73%) 2.1875\n",
            "2m 43s (- 0m 59s) (5130 73%) 2.3467\n",
            "2m 43s (- 0m 59s) (5140 73%) 2.1665\n",
            "2m 43s (- 0m 58s) (5150 73%) 2.2969\n",
            "2m 44s (- 0m 58s) (5160 73%) 2.4543\n",
            "2m 44s (- 0m 58s) (5170 73%) 2.5791\n",
            "2m 44s (- 0m 57s) (5180 74%) 1.4016\n",
            "2m 45s (- 0m 57s) (5190 74%) 1.9077\n",
            "2m 45s (- 0m 57s) (5200 74%) 2.1268\n",
            "2m 45s (- 0m 56s) (5210 74%) 2.0928\n",
            "2m 46s (- 0m 56s) (5220 74%) 1.5166\n",
            "2m 46s (- 0m 56s) (5230 74%) 2.2876\n",
            "2m 46s (- 0m 55s) (5240 74%) 2.1171\n",
            "2m 46s (- 0m 55s) (5250 75%) 2.0164\n",
            "2m 47s (- 0m 55s) (5260 75%) 2.5708\n",
            "2m 47s (- 0m 55s) (5270 75%) 2.2068\n",
            "2m 48s (- 0m 54s) (5280 75%) 1.8002\n",
            "2m 48s (- 0m 54s) (5290 75%) 1.9380\n",
            "2m 48s (- 0m 54s) (5300 75%) 2.1687\n",
            "2m 48s (- 0m 53s) (5310 75%) 2.0880\n",
            "2m 49s (- 0m 53s) (5320 76%) 1.7441\n",
            "2m 49s (- 0m 53s) (5330 76%) 1.5766\n",
            "2m 49s (- 0m 52s) (5340 76%) 2.1338\n",
            "2m 50s (- 0m 52s) (5350 76%) 2.3092\n",
            "2m 50s (- 0m 52s) (5360 76%) 2.0877\n",
            "2m 50s (- 0m 51s) (5370 76%) 2.2488\n",
            "2m 51s (- 0m 51s) (5380 76%) 2.1904\n",
            "2m 51s (- 0m 51s) (5390 77%) 2.0541\n",
            "2m 51s (- 0m 50s) (5400 77%) 1.7663\n",
            "2m 52s (- 0m 50s) (5410 77%) 1.9393\n",
            "2m 52s (- 0m 50s) (5420 77%) 2.1229\n",
            "2m 52s (- 0m 49s) (5430 77%) 1.6906\n",
            "2m 53s (- 0m 49s) (5440 77%) 2.4671\n",
            "2m 53s (- 0m 49s) (5450 77%) 2.1589\n",
            "2m 53s (- 0m 49s) (5460 78%) 1.7831\n",
            "2m 54s (- 0m 48s) (5470 78%) 2.1484\n",
            "2m 54s (- 0m 48s) (5480 78%) 2.0222\n",
            "2m 54s (- 0m 48s) (5490 78%) 2.3319\n",
            "2m 54s (- 0m 47s) (5500 78%) 2.4099\n",
            "2m 55s (- 0m 47s) (5510 78%) 2.0442\n",
            "2m 55s (- 0m 47s) (5520 78%) 1.9921\n",
            "2m 55s (- 0m 46s) (5530 79%) 2.1259\n",
            "2m 56s (- 0m 46s) (5540 79%) 1.6663\n",
            "2m 56s (- 0m 46s) (5550 79%) 1.9598\n",
            "2m 56s (- 0m 45s) (5560 79%) 2.0002\n",
            "2m 57s (- 0m 45s) (5570 79%) 2.3244\n",
            "2m 57s (- 0m 45s) (5580 79%) 2.4216\n",
            "2m 57s (- 0m 44s) (5590 79%) 2.2379\n",
            "2m 58s (- 0m 44s) (5600 80%) 1.9129\n",
            "2m 58s (- 0m 44s) (5610 80%) 1.8924\n",
            "2m 58s (- 0m 43s) (5620 80%) 2.4290\n",
            "2m 59s (- 0m 43s) (5630 80%) 2.3814\n",
            "2m 59s (- 0m 43s) (5640 80%) 2.1413\n",
            "2m 59s (- 0m 42s) (5650 80%) 2.1877\n",
            "2m 59s (- 0m 42s) (5660 80%) 1.9618\n",
            "3m 0s (- 0m 42s) (5670 81%) 1.7558\n",
            "3m 0s (- 0m 41s) (5680 81%) 1.8675\n",
            "3m 0s (- 0m 41s) (5690 81%) 1.9323\n",
            "3m 1s (- 0m 41s) (5700 81%) 1.6757\n",
            "3m 1s (- 0m 40s) (5710 81%) 1.8088\n",
            "3m 1s (- 0m 40s) (5720 81%) 1.7172\n",
            "3m 1s (- 0m 40s) (5730 81%) 1.6971\n",
            "3m 2s (- 0m 40s) (5740 82%) 1.9355\n",
            "3m 2s (- 0m 39s) (5750 82%) 2.1383\n",
            "3m 2s (- 0m 39s) (5760 82%) 1.7327\n",
            "3m 3s (- 0m 39s) (5770 82%) 1.5327\n",
            "3m 3s (- 0m 38s) (5780 82%) 1.7157\n",
            "3m 3s (- 0m 38s) (5790 82%) 2.1774\n",
            "3m 4s (- 0m 38s) (5800 82%) 1.4626\n",
            "3m 4s (- 0m 37s) (5810 83%) 1.8509\n",
            "3m 4s (- 0m 37s) (5820 83%) 1.8518\n",
            "3m 4s (- 0m 37s) (5830 83%) 2.0456\n",
            "3m 5s (- 0m 36s) (5840 83%) 2.1778\n",
            "3m 5s (- 0m 36s) (5850 83%) 2.3832\n",
            "3m 5s (- 0m 36s) (5860 83%) 2.2083\n",
            "3m 6s (- 0m 35s) (5870 83%) 2.2910\n",
            "3m 6s (- 0m 35s) (5880 84%) 2.3564\n",
            "3m 6s (- 0m 35s) (5890 84%) 2.1145\n",
            "3m 6s (- 0m 34s) (5900 84%) 1.5285\n",
            "3m 7s (- 0m 34s) (5910 84%) 1.8457\n",
            "3m 7s (- 0m 34s) (5920 84%) 1.6514\n",
            "3m 7s (- 0m 33s) (5930 84%) 1.9488\n",
            "3m 8s (- 0m 33s) (5940 84%) 1.5090\n",
            "3m 8s (- 0m 33s) (5950 85%) 2.0396\n",
            "3m 8s (- 0m 32s) (5960 85%) 2.2920\n",
            "3m 9s (- 0m 32s) (5970 85%) 2.1343\n",
            "3m 9s (- 0m 32s) (5980 85%) 2.2286\n",
            "3m 9s (- 0m 31s) (5990 85%) 2.1108\n",
            "3m 10s (- 0m 31s) (6000 85%) 1.8981\n",
            "3m 10s (- 0m 31s) (6010 85%) 2.2929\n",
            "3m 10s (- 0m 31s) (6020 86%) 2.4373\n",
            "3m 11s (- 0m 30s) (6030 86%) 2.3194\n",
            "3m 11s (- 0m 30s) (6040 86%) 2.0868\n",
            "3m 11s (- 0m 30s) (6050 86%) 1.6701\n",
            "3m 11s (- 0m 29s) (6060 86%) 1.8404\n",
            "3m 12s (- 0m 29s) (6070 86%) 1.7727\n",
            "3m 12s (- 0m 29s) (6080 86%) 2.0623\n",
            "3m 12s (- 0m 28s) (6090 87%) 2.3782\n",
            "3m 13s (- 0m 28s) (6100 87%) 2.0728\n",
            "3m 13s (- 0m 28s) (6110 87%) 2.0913\n",
            "3m 13s (- 0m 27s) (6120 87%) 2.0134\n",
            "3m 14s (- 0m 27s) (6130 87%) 2.0076\n",
            "3m 14s (- 0m 27s) (6140 87%) 1.7405\n",
            "3m 14s (- 0m 26s) (6150 87%) 1.5484\n",
            "3m 15s (- 0m 26s) (6160 88%) 1.8076\n",
            "3m 15s (- 0m 26s) (6170 88%) 2.0383\n",
            "3m 15s (- 0m 25s) (6180 88%) 1.4800\n",
            "3m 15s (- 0m 25s) (6190 88%) 2.0746\n",
            "3m 16s (- 0m 25s) (6200 88%) 1.6647\n",
            "3m 16s (- 0m 24s) (6210 88%) 1.5627\n",
            "3m 16s (- 0m 24s) (6220 88%) 1.5946\n",
            "3m 17s (- 0m 24s) (6230 89%) 2.0627\n",
            "3m 17s (- 0m 24s) (6240 89%) 2.1283\n",
            "3m 17s (- 0m 23s) (6250 89%) 2.1183\n",
            "3m 17s (- 0m 23s) (6260 89%) 1.9245\n",
            "3m 18s (- 0m 23s) (6270 89%) 1.9470\n",
            "3m 18s (- 0m 22s) (6280 89%) 2.1084\n",
            "3m 18s (- 0m 22s) (6290 89%) 1.9366\n",
            "3m 19s (- 0m 22s) (6300 90%) 2.2490\n",
            "3m 19s (- 0m 21s) (6310 90%) 1.9280\n",
            "3m 19s (- 0m 21s) (6320 90%) 2.2016\n",
            "3m 20s (- 0m 21s) (6330 90%) 1.8997\n",
            "3m 20s (- 0m 20s) (6340 90%) 1.8300\n",
            "3m 20s (- 0m 20s) (6350 90%) 2.0405\n",
            "3m 21s (- 0m 20s) (6360 90%) 2.2063\n",
            "3m 21s (- 0m 19s) (6370 91%) 1.7345\n",
            "3m 21s (- 0m 19s) (6380 91%) 1.7841\n",
            "3m 22s (- 0m 19s) (6390 91%) 2.3067\n",
            "3m 22s (- 0m 18s) (6400 91%) 2.2106\n",
            "3m 22s (- 0m 18s) (6410 91%) 2.1276\n",
            "3m 23s (- 0m 18s) (6420 91%) 2.1507\n",
            "3m 23s (- 0m 18s) (6430 91%) 2.1593\n",
            "3m 23s (- 0m 17s) (6440 92%) 2.0509\n",
            "3m 24s (- 0m 17s) (6450 92%) 2.2663\n",
            "3m 24s (- 0m 17s) (6460 92%) 2.0531\n",
            "3m 24s (- 0m 16s) (6470 92%) 1.7697\n",
            "3m 25s (- 0m 16s) (6480 92%) 1.9739\n",
            "3m 25s (- 0m 16s) (6490 92%) 1.7433\n",
            "3m 25s (- 0m 15s) (6500 92%) 1.9798\n",
            "3m 25s (- 0m 15s) (6510 93%) 1.9178\n",
            "3m 26s (- 0m 15s) (6520 93%) 2.0107\n",
            "3m 26s (- 0m 14s) (6530 93%) 1.9661\n",
            "3m 26s (- 0m 14s) (6540 93%) 2.0725\n",
            "3m 27s (- 0m 14s) (6550 93%) 1.7469\n",
            "3m 27s (- 0m 13s) (6560 93%) 1.9663\n",
            "3m 27s (- 0m 13s) (6570 93%) 2.0965\n",
            "3m 28s (- 0m 13s) (6580 94%) 1.9543\n",
            "3m 28s (- 0m 12s) (6590 94%) 2.0261\n",
            "3m 28s (- 0m 12s) (6600 94%) 2.1056\n",
            "3m 29s (- 0m 12s) (6610 94%) 1.8446\n",
            "3m 29s (- 0m 12s) (6620 94%) 1.8945\n",
            "3m 29s (- 0m 11s) (6630 94%) 1.3317\n",
            "3m 29s (- 0m 11s) (6640 94%) 1.8041\n",
            "3m 30s (- 0m 11s) (6650 95%) 1.8941\n",
            "3m 30s (- 0m 10s) (6660 95%) 2.1464\n",
            "3m 30s (- 0m 10s) (6670 95%) 2.2639\n",
            "3m 31s (- 0m 10s) (6680 95%) 1.7227\n",
            "3m 31s (- 0m 9s) (6690 95%) 1.8800\n",
            "3m 31s (- 0m 9s) (6700 95%) 1.9758\n",
            "3m 31s (- 0m 9s) (6710 95%) 2.1900\n",
            "3m 32s (- 0m 8s) (6720 96%) 2.0960\n",
            "3m 32s (- 0m 8s) (6730 96%) 2.2222\n",
            "3m 32s (- 0m 8s) (6740 96%) 1.8330\n",
            "3m 33s (- 0m 7s) (6750 96%) 1.4591\n",
            "3m 33s (- 0m 7s) (6760 96%) 2.1863\n",
            "3m 33s (- 0m 7s) (6770 96%) 1.8445\n",
            "3m 33s (- 0m 6s) (6780 96%) 1.2159\n",
            "3m 34s (- 0m 6s) (6790 97%) 1.7275\n",
            "3m 34s (- 0m 6s) (6800 97%) 2.0903\n",
            "3m 34s (- 0m 5s) (6810 97%) 1.6117\n",
            "3m 34s (- 0m 5s) (6820 97%) 1.7659\n",
            "3m 35s (- 0m 5s) (6830 97%) 1.9499\n",
            "3m 35s (- 0m 5s) (6840 97%) 2.0497\n",
            "3m 35s (- 0m 4s) (6850 97%) 2.1465\n",
            "3m 36s (- 0m 4s) (6860 98%) 1.5233\n",
            "3m 36s (- 0m 4s) (6870 98%) 1.3791\n",
            "3m 36s (- 0m 3s) (6880 98%) 1.5288\n",
            "3m 36s (- 0m 3s) (6890 98%) 1.3260\n",
            "3m 37s (- 0m 3s) (6900 98%) 2.1373\n",
            "3m 37s (- 0m 2s) (6910 98%) 1.9081\n",
            "3m 37s (- 0m 2s) (6920 98%) 2.0798\n",
            "3m 38s (- 0m 2s) (6930 99%) 1.6920\n",
            "3m 38s (- 0m 1s) (6940 99%) 1.7043\n",
            "3m 38s (- 0m 1s) (6950 99%) 2.1409\n",
            "3m 38s (- 0m 1s) (6960 99%) 2.1235\n",
            "3m 39s (- 0m 0s) (6970 99%) 2.0507\n",
            "3m 39s (- 0m 0s) (6980 99%) 1.9879\n",
            "3m 39s (- 0m 0s) (6990 99%) 1.9852\n",
            "3m 40s (- 0m 0s) (7000 100%) 1.9899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K_98rBd8dmU"
      },
      "source": [
        "#compute BLEU-4 score\n",
        "def compute_bleu(output, reference):\n",
        "    cc = SmoothingFunction()\n",
        "    if len(reference) == 3:\n",
        "        weights = (0.33,0.33,0.33)\n",
        "    else:\n",
        "        weights = (0.25,0.25,0.25,0.25)\n",
        "    return sentence_bleu([reference], output,weights=weights,smoothing_function=cc.method1)\n",
        "\n",
        "def evaluate(encoder, decoder, input_tensor, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        # input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(vocab.idx2char[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-X9P5De7wO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "e817a7c0-ed2a-4c84-fd3b-de48cda3ecc3"
      },
      "source": [
        "pairs=get_pair('test.json')\n",
        "outputs=[]\n",
        "reference=[]\n",
        "for i in range(10):\n",
        "        pair = random.choice(pairs)\n",
        "        input_tensor,target_tensor=tensorsFromPair(pair)\n",
        "        print('input :', pair[0])\n",
        "        print('target :', pair[1])\n",
        "        output_words,attention= evaluate(encoder1, decoder1, input_tensor)\n",
        "        print('pred :',\"\".join(output_words[:-1]))\n",
        "        outputs.append(\"\".join(output_words[:-1]))\n",
        "        reference.append(pair[1])\n",
        "        print('==============================================')\n",
        "print('BLEU-4 score :',compute_bleu(outputs,reference))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input : enxt\n",
            "target : next\n",
            "pred : pore\n",
            "==============================================\n",
            "input : scadual\n",
            "target : schedule\n",
            "pred : pore\n",
            "==============================================\n",
            "input : powerfull\n",
            "target : powerful\n",
            "pred : pore\n",
            "==============================================\n",
            "input : dirven\n",
            "target : driven\n",
            "pred : pore\n",
            "==============================================\n",
            "input : recetion\n",
            "target : recession\n",
            "pred : pore\n",
            "==============================================\n",
            "input : leval\n",
            "target : level\n",
            "pred : pe\n",
            "==============================================\n",
            "input : firery\n",
            "target : fiery\n",
            "pred : pore\n",
            "==============================================\n",
            "input : decant\n",
            "target : decent\n",
            "pred : pore\n",
            "==============================================\n",
            "input : leason\n",
            "target : lesson\n",
            "pred : pore\n",
            "==============================================\n",
            "input : havest\n",
            "target : harvest\n",
            "pred : pont\n",
            "==============================================\n",
            "BLEU-4 score : 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}